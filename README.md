# ğŸ”¬ Auto-Research Agent 2.0

**AI-Powered Multi-Agent Research Platform with Streamlit Web Interface**

> ğŸŒŸ **NEW**: Complete web application with authentication, subscription tiers, and real-time research workflow!

---

## ğŸ“Œ Overview

Auto-Research Agent 2.0 is an autonomous AI research platform that performs comprehensive research on any topic. The system uses 9 specialized AI agents working together to search, analyze, verify facts, and generate professional reports with citations.

**What's New in v2.0:**
- âœ¨ **Streamlit Web UI** - Modern, responsive web interface
- ğŸ” **User Authentication** - Secure login/signup with JWT tokens
- ğŸ’ **Subscription Tiers** - Free (5 researches/day) and Premium (unlimited)
- ğŸ“Š **Real-time Dashboard** - Track usage, view history, manage settings
- ğŸš€ **3 Research Modes** - Quick, Standard, and Deep research
- ğŸ’¾ **Smart Caching** - Instant results for repeated queries
- ğŸ“¥ **Multi-format Export** - PDF, DOCX, Markdown downloads

---

## âœ¨ Key Features

### Core Research Capabilities
- ğŸ¤– **9 AI Agents** - Query expansion, search, summarization, fact-checking, writing, editing, citations
- ğŸ” **Multi-Source Search** - Wikipedia, Brave Search, SerpAPI, Exa with automatic fallbacks
- âœ… **Fact Verification** - Cross-reference claims with confidence scoring
- ğŸ“š **Smart Citations** - APA, MLA, Chicago formatting with inline references
- ğŸ“ˆ **Credibility Scoring** - Source reliability analysis (0-100 scale)
- ğŸ”„ **Iterative Research** - Gap detection and progressive information gathering

### Web Application Features
- ğŸ¨ **Modern Dark Theme** - Professional, eye-friendly interface
- ğŸ‘¤ **User Management** - Secure accounts with password hashing (bcrypt)
- ğŸ“Š **Usage Analytics** - Daily limits, cache stats, research history
- ğŸ—‚ï¸ **Research History** - Download previous reports (MD, PDF, DOCX)
- âš™ï¸ **Settings Page** - Account info and premium upgrade options
- ğŸ“± **Responsive Design** - Works on desktop and mobile

---

## ğŸ†“ Free vs ğŸ’ Premium

| Feature | Free Tier | Premium Tier |
|---------|-----------|--------------|
| **Daily Limit** | 5 researches | â™¾ï¸ Unlimited |
| **Research Modes** | Quick + Standard | Quick + Standard + **Deep** |
| **Max Sources** | 5 sources | 15+ sources |
| **Word Limit** | 2,000 words | 5,000+ words |
| **Export Formats** | PDF + Markdown | PDF + **DOCX** + Markdown |
| **Citations** | Basic | APA + MLA + Chicago |
| **Charts** | âŒ | âœ… Visualizations |
| **Priority** | Standard | Priority processing |
| **Cost** | **$0/month** | **$29/month** |

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.9+**
- **API Keys** (get free keys in 5 minutes):
  - **Groq** (free): https://console.groq.com
  - **Google Gemini** (free): https://aistudio.google.com/apikey
  - **OpenAI** (optional, paid): https://platform.openai.com/api-keys

### Installation

**1. Clone Repository**
```powershell
git clone <your-repo-url>
cd "Auto Reasearch Agent"
```

**2. Run Setup Script**
```powershell
.\setup.ps1
```

This automatically:
- Creates virtual environment
- Installs all dependencies (streamlit, bcrypt, matplotlib, etc.)
- Sets up directory structure

**3. Configure API Keys**
```powershell
# Copy template
Copy-Item .env.example .env

# Edit .env and add your keys
notepad .env
```

Required keys:
```env
GROQ_API_KEY=gsk_your_key_here
GEMINI_API_KEY=AIzaSy_your_key_here
```

Optional (for premium features):
```env
OPENAI_API_KEY=sk-proj-your_key_here
ANTHROPIC_API_KEY=sk-ant-your_key_here
```

**4. Launch Application**
```powershell
# Activate virtual environment
.\venv\Scripts\Activate

# Start Streamlit server
streamlit run app.py
```

The app opens at: **http://localhost:8501** ğŸ‰

---

## ğŸ’» Usage Guide

### 1ï¸âƒ£ Create Account

- Click **"Sign Up"** tab
- Enter name, email, username, password
- Account created as **Free tier** by default

### 2ï¸âƒ£ Login

- Enter username/email and password
- Access your personalized dashboard

### 3ï¸âƒ£ Start Research

**Select Research Mode:**
- âš¡ **Quick** - Fast overview (2 sources, ~500 words, 30 sec)
- ğŸ“ **Standard** - Balanced research (5 sources, ~2000 words, 2 min)
- ğŸ” **Deep** - Comprehensive (15+ sources, 5000+ words, 5 min) *Premium only*

**Enter Query:**
```
Example: "Impact of artificial intelligence in healthcare"
```

**Watch Live Progress:**
- ğŸ“ Query processing
- ğŸ’¾ Cache check
- ğŸ” Multi-source search
- ğŸ¯ Credibility scoring
- ğŸ¤– AI workflow execution
- âœ… Report generation

### 4ï¸âƒ£ View Results

**Report Tab:**
- Full research report with citations
- Professional formatting

**Sources Tab:**
- View all sources with credibility scores
- Expandable details (URL, snippet)

**Statistics Tab:**
- Word count, sources used
- Coverage score, time elapsed
- Facts verified count

**Export Tab:**
- ğŸ“„ Download Markdown
- ğŸ“• Download PDF
- ğŸ“˜ Download DOCX *(Premium)*

### 5ï¸âƒ£ Access History

- ğŸ“š Navigate to **"History"** page
- View all past researches
- Download previous reports (MD, PDF, DOCX)
- See metadata (tier, sources, word count)

### 6ï¸âƒ£ Check Statistics

- ğŸ“Š Navigate to **"Statistics"** page
- View today's usage (X / 5 for free)
- Cache hit rate and efficiency
- Clear cache if needed

### 7ï¸âƒ£ Manage Settings

- âš™ï¸ Navigate to **"Settings"** page
- View account information
- See upgrade options (Free users)
- Contact info for premium upgrade

---

## ğŸ“Š Research Modes Explained

### âš¡ Quick Mode
- **Purpose:** Fast fact-checking or quick overviews
- **Sources:** 2 reliable sources
- **Length:** ~500 words
- **Time:** 30-60 seconds
- **Best For:** Quick answers, fact verification, brief summaries

### ğŸ“ Standard Mode (Recommended)
- **Purpose:** Balanced, comprehensive research
- **Sources:** 5 high-quality sources
- **Length:** ~2000 words
- **Time:** 1-2 minutes
- **Best For:** Essays, blog posts, presentations, general research

### ğŸ” Deep Mode (Premium)
- **Purpose:** Academic-level, exhaustive research
- **Sources:** 15+ peer-reviewed sources
- **Length:** 5000+ words
- **Time:** 4-6 minutes
- **Features:** Charts, advanced fact-checking, gap detection
- **Best For:** Thesis, research papers, technical reports

---

## ğŸ—ï¸ System Architecture

### Frontend (Streamlit)
- **app.py** - Main web application (765 lines)
  - `AutoResearchApp` class with 10 methods
  - Login/signup forms with validation
  - Dashboard with 4 pages (Research, History, Statistics, Settings)
  - Real-time progress indicators
  - Download buttons for exports

### Backend Modules

**Authentication (`auth/`)**
- `authentication.py` - User database, usage tracking, JWT tokens
- `password_recovery.py` - Password reset functionality

**Research (`research/`)**
- `research_modes.py` - 3 modes with configuration
- `query_processor.py` - Async query expansion and correction

**Orchestrator (`orchestrator/`)**
- `tiered_workflow.py` - Main workflow with 9 stages
  - Stage 1: Query expansion
  - Stage 2-5: Iterative search and fact-checking
  - Stage 6: Report generation
  - Stage 7: Editing (Premium)
  - Stage 8: Citations
  - Stage 9: Publishing

**AI Agents (`agents/`)**
- `query_expansion.py` - Break down topics
- `search_agent.py` - Web search
- `summarizer.py` - Extract key facts
- `fact_checker.py` - Verify claims
- `gap_finder.py` - Identify missing info
- `writer.py` - Generate reports
- `editor.py` - Refine text
- `citation.py` - Format references
- `publisher.py` - Export files

**Utilities (`utils/`)**
- `search_engines.py` - Multi-source search with fallbacks
- `cache_system.py` - Query caching with similarity matching
- `credibility_scorer.py` - Source reliability analysis
- `chart_generator.py` - Data visualizations
- `advanced_exports.py` - PDF/DOCX generation

**Subscription (`subscription/`)**
- `manager.py` - Tier management and usage tracking

**Models (`models/`)**
- `router.py` - AI model selection by tier

---

## ğŸ“ Project Structure

```
Auto Reasearch Agent/
â”œâ”€â”€ app.py                      # ğŸš€ Main Streamlit application (START HERE)
â”œâ”€â”€ config.py                   # Configuration settings
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ setup.ps1                   # Automated setup script
â”‚
â”œâ”€â”€ agents/                     # 9 specialized AI agents
â”‚   â”œâ”€â”€ query_expansion.py
â”‚   â”œâ”€â”€ search_agent.py
â”‚   â”œâ”€â”€ summarizer.py
â”‚   â”œâ”€â”€ fact_checker.py
â”‚   â”œâ”€â”€ gap_finder.py
â”‚   â”œâ”€â”€ writer.py
â”‚   â”œâ”€â”€ editor.py
â”‚   â”œâ”€â”€ citation.py
â”‚   â””â”€â”€ publisher.py
â”‚
â”œâ”€â”€ auth/                       # Authentication system
â”‚   â”œâ”€â”€ authentication.py       # Users, JWT, usage tracking
â”‚   â””â”€â”€ password_recovery.py    # Password reset
â”‚
â”œâ”€â”€ orchestrator/               # Research workflow
â”‚   â””â”€â”€ tiered_workflow.py      # 9-stage pipeline
â”‚
â”œâ”€â”€ research/                   # Research components
â”‚   â”œâ”€â”€ research_modes.py       # Quick/Standard/Deep modes
â”‚   â””â”€â”€ query_processor.py      # Query analysis
â”‚
â”œâ”€â”€ subscription/               # Subscription management
â”‚   â””â”€â”€ manager.py              # Tiers, limits, features
â”‚
â”œâ”€â”€ utils/                      # Utilities
â”‚   â”œâ”€â”€ search_engines.py       # Multi-source search
â”‚   â”œâ”€â”€ cache_system.py         # Result caching
â”‚   â”œâ”€â”€ credibility_scorer.py   # Source scoring
â”‚   â”œâ”€â”€ chart_generator.py      # Visualizations
â”‚   â””â”€â”€ advanced_exports.py     # PDF/DOCX export
â”‚
â”œâ”€â”€ models/                     # AI model routing
â”‚   â””â”€â”€ router.py               # Model selection
â”‚
â”œâ”€â”€ database/                   # SQLite databases
â”œâ”€â”€ cache/                      # Cached results
â”œâ”€â”€ output_files/               # Generated reports
â”œâ”€â”€ logs/                       # Application logs
â”‚
â””â”€â”€ docs/                       # Documentation
    â”œâ”€â”€ UPGRADE_GUIDE.md        # Complete feature guide
    â”œâ”€â”€ UPGRADE_SUMMARY.md      # Quick overview
    â””â”€â”€ TROUBLESHOOTING.md      # Common issues
```

---

## ğŸ”§ Configuration

### Environment Variables (.env)

```env
# Required: Free tier models
GROQ_API_KEY=gsk_...
GEMINI_API_KEY=AIzaSy...

# Optional: Premium tier models
OPENAI_API_KEY=sk-proj-...
ANTHROPIC_API_KEY=sk-ant-...

# Optional: Search APIs
BRAVE_API_KEY=BSA...
SERPAPI_KEY=...
EXA_API_KEY=...

# Application
SECRET_KEY=your-secret-key-here
DEBUG=false
```

### config.py Settings

```python
# Output
OUTPUT_DIR = "output_files"
CACHE_DIR = "cache"

# Search
DEFAULT_SEARCH_RESULTS = 10
MAX_CONCURRENT_SEARCHES = 5

# Reports
DEFAULT_FORMAT = "pdf"
CITATION_STYLE = "APA"

# Subscription
FREE_DAILY_LIMIT = 5
CACHE_TTL_HOURS = 24
```

---

## ğŸ› Troubleshooting

### App Won't Start

```powershell
# Check Python version
python --version  # Should be 3.9+

# Reinstall dependencies
pip install -r requirements.txt

# Check for port conflicts
netstat -ano | findstr :8501
```

### API Key Errors

```powershell
# Verify .env file exists
Get-Content .env

# Check key format
# Groq: starts with "gsk_"
# Gemini: starts with "AIzaSy"
```

### Database Errors

```powershell
# Reset database
Remove-Item database/*.db
# Restart app (recreates tables)
```

### Cache Issues

- Clear cache from Statistics page
- Or delete manually:
```powershell
Remove-Item -Recurse cache/*
```

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---


## ğŸŒŸ Acknowledgments

Built with:
- **Streamlit** - Web framework
- **OpenAI GPT-4** - Language models
- **Groq** - Fast inference
- **Google Gemini** - Free AI models
- **SQLite** - Database
- **BeautifulSoup** - Web scraping
- **Matplotlib** - Charts
- **bcrypt** - Password hashing

---

**Made by Sahil Garg**
